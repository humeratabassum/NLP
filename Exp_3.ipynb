{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5cdSTfZAtyvGIHo9YmjX0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/humeratabassum/NLP/blob/main/Exp_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP Text Representation Methods – Code Overview\n",
        "This code demonstrates four popular ways to convert text into numerical features using a sample corpus of three sentences. These methods are commonly used in Natural Language Processing (NLP) tasks like classification or clustering."
      ],
      "metadata": {
        "id": "e33X1ahNySj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. One-Hot Encoding\n",
        "Function: one_hot_encoding(corpus)\n",
        "\n",
        "Converts each unique word in the corpus into a binary vector.\n",
        "\n",
        "For every sentence, a vector is created where:\n",
        "\n",
        "1 → word is present\n",
        "\n",
        "0 → word is absent\n",
        "\n",
        "Example: [0, 1, 0, 1, 0] (depends on word order in the dictionary)\n",
        "\n",
        "#3. Bag of Words (BoW)\n",
        "Function: bag_of_words(corpus)\n",
        "\n",
        "Uses CountVectorizer from sklearn.\n",
        "\n",
        "Converts each sentence into a vector of word frequencies.\n",
        "\n",
        "It counts how many times each word appears in the sentence.\n",
        "\n",
        "Output: A 2D matrix where:\n",
        "\n",
        "Rows = sentences\n",
        "\n",
        "Columns = words\n",
        "\n",
        "Values = word count in each sentence\n",
        "\n",
        "#4. TF-IDF (Term Frequency - Inverse Document Frequency)\n",
        "Function: tf_idf(corpus)\n",
        "\n",
        "Uses TfidfVectorizer from sklearn.\n",
        "\n",
        "Similar to BoW, but instead of just counting, it calculates how important each word is.\n",
        "\n",
        "Common words across all sentences get lower weight.\n",
        "\n",
        "Output: Matrix with TF-IDF scores for each word per sentence.\n",
        "\n",
        "#5. N-Grams\n",
        "Function: n_grams(corpus, n=2)\n",
        "\n",
        "Splits text into sequences of 'n' consecutive words.\n",
        "\n",
        "Example (for bigrams, n=2): \"I love\" → ('I', 'love')\n",
        "\n",
        "Helps to capture context and word relationships better than individual words.\n",
        "\n",
        "Output: List of n-grams for each sentence.\n",
        "\n",
        "#6. Execution and Output\n",
        "Each function is called with the corpus, and the results are printed:\n",
        "\n",
        "✅ One-Hot Vectors and their Word Index Mapping\n",
        "\n",
        "✅ BoW Vectors and Feature Words\n",
        "\n",
        "✅ TF-IDF Vectors and Feature Words\n",
        "\n",
        "✅ 2-Grams from each sentence"
      ],
      "metadata": {
        "id": "zDOmnpgdyWd0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY8KTGNZxxSa",
        "outputId": "79000161-28f9-4112-981e-eeb9f202943a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "One-Hot Encoding:\n",
            "Word to Index: {'learning': 0, 'I': 1, 'is': 2, 'Python': 3, 'love': 4, 'an': 5, 'in': 6, 'programming': 7, 'data': 8, 'science.': 9, 'am': 10, 'machine': 11, 'language': 12, 'with': 13, 'for': 14, 'Python.': 15, 'amazing': 16}\n",
            "One-Hot Vectors:\n",
            " [[0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1]\n",
            " [1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0]]\n",
            "\n",
            "Bag of Words (BoW):\n",
            "BoW Vectors:\n",
            " [[0 0 0 0 0 1 0 0 0 1 0 1 1 0 0]\n",
            " [0 1 1 1 1 0 1 1 0 0 0 0 1 1 0]\n",
            " [1 0 0 0 0 0 0 0 2 0 1 0 1 0 1]]\n",
            "BoW Words: ['am' 'amazing' 'an' 'data' 'for' 'in' 'is' 'language' 'learning' 'love'\n",
            " 'machine' 'programming' 'python' 'science' 'with']\n",
            "\n",
            "TF-IDF Representation:\n",
            "TF-IDF Vectors:\n",
            " [[0.         0.         0.         0.         0.         0.54645401\n",
            "  0.         0.         0.         0.54645401 0.         0.54645401\n",
            "  0.32274454 0.         0.        ]\n",
            " [0.         0.36888498 0.36888498 0.36888498 0.36888498 0.\n",
            "  0.36888498 0.36888498 0.         0.         0.         0.\n",
            "  0.21786941 0.36888498 0.        ]\n",
            " [0.36888498 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.73776997 0.         0.36888498 0.\n",
            "  0.21786941 0.         0.36888498]]\n",
            "TF-IDF Words: ['am' 'amazing' 'an' 'data' 'for' 'in' 'is' 'language' 'learning' 'love'\n",
            " 'machine' 'programming' 'python' 'science' 'with']\n",
            "\n",
            "N-Grams (2-Grams):\n",
            "Sentence 1 N-Grams: [('I', 'love'), ('love', 'programming'), ('programming', 'in'), ('in', 'Python.')]\n",
            "Sentence 2 N-Grams: [('Python', 'is'), ('is', 'an'), ('an', 'amazing'), ('amazing', 'language'), ('language', 'for'), ('for', 'data'), ('data', 'science.')]\n",
            "Sentence 3 N-Grams: [('I', 'am'), ('am', 'learning'), ('learning', 'machine'), ('machine', 'learning'), ('learning', 'with'), ('with', 'Python.')]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import numpy as np\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# Sample Text Data\n",
        "corpus = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Python is an amazing language for data science.\",\n",
        "    \"I am learning machine learning with Python.\"\n",
        "]\n",
        "\n",
        "# 1. One-Hot Encoding\n",
        "def one_hot_encoding(corpus):\n",
        "    words = list(set(' '.join(corpus).split()))  # Unique words\n",
        "    word_to_index = {word: idx for idx, word in enumerate(words)}  # Mapping word to index\n",
        "    one_hot_vectors = []\n",
        "\n",
        "    for text in corpus:\n",
        "        vector = [0] * len(words)\n",
        "        for word in text.split():\n",
        "            vector[word_to_index[word]] = 1\n",
        "        one_hot_vectors.append(vector)\n",
        "\n",
        "    return one_hot_vectors, word_to_index\n",
        "\n",
        "# 2. Bag of Words (BoW)\n",
        "def bag_of_words(corpus):\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "    return X.toarray(), vectorizer.get_feature_names_out()\n",
        "\n",
        "# 3. TF-IDF\n",
        "def tf_idf(corpus):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "    return X.toarray(), vectorizer.get_feature_names_out()\n",
        "\n",
        "# 4. N-Grams (2-Grams)\n",
        "def n_grams(corpus, n=2):\n",
        "    ngram_list = []\n",
        "    for text in corpus:\n",
        "        tokens = text.split()\n",
        "        ngram_list.append(list(ngrams(tokens, n)))  # List of n-grams\n",
        "    return ngram_list\n",
        "\n",
        "# Running the functions and printing results:\n",
        "\n",
        "# One-Hot Encoding\n",
        "one_hot_vectors, word_to_index = one_hot_encoding(corpus)\n",
        "print(\"\\nOne-Hot Encoding:\")\n",
        "print(\"Word to Index:\", word_to_index)\n",
        "print(\"One-Hot Vectors:\\n\", np.array(one_hot_vectors))\n",
        "\n",
        "# Bag of Words (BoW)\n",
        "bow_vectors, bow_words = bag_of_words(corpus)\n",
        "print(\"\\nBag of Words (BoW):\")\n",
        "print(\"BoW Vectors:\\n\", bow_vectors)\n",
        "print(\"BoW Words:\", bow_words)\n",
        "\n",
        "# TF-IDF\n",
        "tfidf_vectors, tfidf_words = tf_idf(corpus)\n",
        "print(\"\\nTF-IDF Representation:\")\n",
        "print(\"TF-IDF Vectors:\\n\", tfidf_vectors)\n",
        "print(\"TF-IDF Words:\", tfidf_words)\n",
        "\n",
        "# N-Grams (2-Grams)\n",
        "ngrams_result = n_grams(corpus, n=2)\n",
        "print(\"\\nN-Grams (2-Grams):\")\n",
        "for idx, ngram in enumerate(ngrams_result):\n",
        "    print(f\"Sentence {idx+1} N-Grams:\", ngram)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xzzZBAMVyKgi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}